<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="stylesheet" href="../css/styles.css" type="text/css">
		<title>CTSN Design - Computer Vision</title>
	</head>
	<body>
		<div id="header">
			<h1>Commuter Tracking Sensor Network</h1>
		</div>
		
		<div id="nav">
			<ul class="navlist">
				<li class="navli"><a href="../index.html">Home</a></li>
				<li class="navlicurr"><a href="../design.html">Design</a></li>
				<li class="navli"><a href="../teambios.html">Team</a></li>
				<li class="navli"><a href="../media.html">Media</a></li>
				<li class="navli"><a href="../resources.html">Resources</a></li>
			</ul>
		</div>
		
		<div id="content">
			<div id="sidebar">
				<ul class="navlist">
					<li><a class="vertnavacurr" href="compvision.html">Computer Vision</a></li>
					<li><a class="vertnava" href="networking.html">Networking</a></li>
					<li><a class="vertnava" href="powermgmt.html">Power Management</a></li>
					<li><a class="vertnava" href="sustainability.html">Sustainability</a></li>
					<li><a class="vertnava" href="userinterface.html">User Interface</a></li>
				</ul>
			</div>
			
			<aside>
				<h4>Important terms</h4>
				<div class="impterm">
					<p><em>Computer Vision:</em></p>
					<p>A field that involves acquisition, processing, analysis and
					identification of images and other real-world data to produce
					numerical or symbolic data.</p>
				</div>
				<div class="impterm">
					<p><em>Algorithm:</em></p>
					<p>A step-by-step procedure for calculations.</p>
				</div>
			</aside>
			
			<div id="section">
				<p>The CTSN consists of modules with onboard image sensors
				and Computer Vision processing capabilities. Relevant data is
				processed locally and the resulting metadata is sent over the
				network to a main node. In order for this to occur in an efficient
				manner, several different computer vision problems were addressed
				by the chosen hardware and associated design.</p>
				<figure class="design">
					<img src="../media/pictures/pixycam.bmp" 
						 alt="PIXYCam CMUCam5" width="400" height="301">
					<figcaption class="design">PIXYCam CMUCam5</figcaption>
				</figure>
				<p>Image acquisition will be handled by the PIXYCam CMUCam. Technical
				specifications are as follows:</p>
				<ul class="speclist">
					<li>Processor: NXP LPC4330, 204 MHz, dual core</li>
					<li>Image sensor: Omnivision OV9715, 1/4", 1280x800</li>
					<li>Lens field-of-view: 75 degrees horizontal, 47 degrees vertical</li>
					<li>Lens type: standard M12 (replaceable)</li>
					<li>Power consumption: 140mA typical</li>
					<li>Power input: USB input (5V) or unregulated input (6V to 10V)</li>
					<li>RAM: 264K bytes</li>
					<li>Flash: 1M bytes</li>
					<li>Available data outputs: UART serial, SPI, I2C, USB, digital, analog</li>
					<li>Dimensions: 2.1" x 2.0" x 1.4"</li>
					<li>Weight: 27 grams</li>
				</ul>
				<p>Three specific design problems were addressed:</p>
				<ol>
					<li>Feature detection, Description and Matching
						<ul><li>Is that a horse, pedestrian, werewolf, ETC?</li></ul>
					</li>
					<li>Object Tracking
						<ul><li>Where is the object is travelling in the frame?</li></ul>
					</li>
					<li>Multi-camera Tracking
						<ul><li>Where in the network is the object located?</li></ul>
					</li>
				</ol>
				<p>The general solution is to find existing implementations of algorithms
				that address each of the areas of concern. A software interface for the 
				PIXYCam can then be utilized to plug in and test the selected algorithm.</p>
				<p>To specifically address the first design problem, three algorithms were
				analyzed in great detail. These included 
				<a class="inline" href="http://www.vision.ee.ethz.ch/~surf/eccv06.pdf" target="_blank">"Speeded up Robust Features"</a>,
				<a class="inline" href="http://www.robots.ox.ac.uk/~vgg/rg/papers/brisk.pdf" target="_blank">"Binary Robust Invariant Scalable Keypoints"</a>, and 
				<a class="inline" href="http://infoscience.epfl.ch/record/175537/files/2069.pdf" target="_blank">"Fast Retina Keypoint"</a>.
				Due to availability of existing implementations in C++, and its exceptional
				performance in average seconds per frame, the FREAK (Fast Retina Keypoint)
				algorithm was chosen.</p>
				<p>Object tracking will be handled via the 
				<a class="inline" href="http://personal.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html" target="_blank">"Predator" (TLD)</a> or the
				<a class="inline" href="http://crcv.ucf.edu/courses/CAP5415/Fall2013/Lecture-10-KLT.pdf" target="_blank">"Kanade-Lucas-Tomasi" (KLT)</a> algorithm.</p>
				<p>Multi-camera tracking will occur by application of the
				<a class="inline" href="http://cvlab.epfl.ch/software/pom/" target="_blank">"Probabilistic Occupancy Map (POM)"</a>.</p>
				<div class="iframecontainer">
					<iframe width="420" height="315" src="http://www.youtube.com/embed/7DpdoOODPRs" allowfullscreen></iframe>
				</div>
				<h4>Risks of CV Implementation</h4>
				<ul>
					<li>Not being able to track subjects across the entire network
					considering the relatively small amount of the trail that is actually
					being observed.</li>
					<li>Not achieving satisfactory results with the image sensor on the 
					PIXYCam due to variation in outdoor conditions.</li>
				</ul>
				<h4>CV Testing Strategy</h4>
				<ul>
					<li>Gather reference video from the trail with the PIXYCam involving various
					subjects and under various conditions.</li>
					<li>Utilize this reference video to test various algorithms for both accuracy
					and computational performance.</li>
				</ul>
			</div>
		</div>
		
		<div id="footer">
			<div id="copyright">CTSN &copy; 2014</div>
			<div id="timestamp">Last updated on:
				<script>document.write(document.lastModified);</script></div>
		</div>
	</body>
</html>